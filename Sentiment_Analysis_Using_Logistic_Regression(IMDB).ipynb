{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextClassificationAndSentimentAnalysis(IMDB).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8m2EWIhhTXVB+lmfFcuWv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhijunm/Text_Mining/blob/master/TextClassificationAndSentimentAnalysis(IMDB).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA5obFVmFksR",
        "colab_type": "code",
        "outputId": "6f464289-db03-4caa-dd23-32d3ccf95063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# tokenization of text\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "# remove stop words\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "# set the language\n",
        "all_stopwords = set(stopwords.words('english')) \n",
        "from typing import List"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24zjXzj2GorS",
        "colab_type": "code",
        "outputId": "652f7a33-36c5-4cb2-f261-97af8a916e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# reading review data with panda frames\n",
        "reviews_data = pd.read_csv('IMDB Dataset.csv')\n",
        "reviews_data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000</td>\n",
              "      <td>50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>49582</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Loved today's show!!! It was a variety and not...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>5</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   review sentiment\n",
              "count                                               50000     50000\n",
              "unique                                              49582         2\n",
              "top     Loved today's show!!! It was a variety and not...  positive\n",
              "freq                                                    5     25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztptx14MPKbD",
        "colab_type": "text"
      },
      "source": [
        "We have 50k revies of which 49582 reviews are unique and have two types of sentiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8J1B2m8O8_2",
        "colab_type": "code",
        "outputId": "0c31e63e-e181-4d72-8be3-4c876314583d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# sentiment counts\n",
        "reviews_data['sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    25000\n",
              "negative    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-EDTsrpPS55",
        "colab_type": "text"
      },
      "source": [
        "The sentiments are either positive or negative and are evenly distributed. Lets reprocess the text using the simple tokenizer we built last time. We call it preprocess_text now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk_v07jfPFwL",
        "colab_type": "code",
        "outputId": "8147840f-50f3-4cdf-e918-499b054f681b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def preprocess_text(text: str) -> List[str]:\n",
        "    # Looking at the text we see that <br></br> which is HTML tag for line break can be a good splitter\n",
        "    # A sentence (atleast well structured) often has a full spot at the end. We use these two for word breaks\n",
        "    pattern1 = re.compile(\"<br /><br />|\\.\")\n",
        "    lines = re.split(pattern1, text)\n",
        "    # you can break a sentence into words using whitespace based split\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        tokens += line.split(\" \")\n",
        "\n",
        "    # lowercase and remove any non-alphanumeric characters from tokens for normalize\n",
        "    normalized_tokens = [re.sub(r\"\\W+\", \"\", token.lower()) for token in tokens]\n",
        "    return  \" \".join([\n",
        "            token\n",
        "            for token in normalized_tokens\n",
        "            if token and token not in all_stopwords and len(tokens) > 1 \n",
        "        ])\n",
        "    \n",
        "\n",
        "  \n",
        "custom_review = \"I hated the film. It was a disaster. Poor direction, bad acting.\"\n",
        "custom_review_tokens = preprocess_text(custom_review)\n",
        "print(custom_review_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hated film disaster poor direction bad acting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZUXfcWPzHtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply preprocessing to review data\n",
        "reviews_data['review'] = reviews_data['review'].apply(preprocess_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgpxir8X6nHK",
        "colab_type": "code",
        "outputId": "f7dcd996-0f12-41aa-b975-b3d8d0dae9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#split the dataset  \n",
        "#train dataset\n",
        "train_reviews=reviews_data.review[:40000]\n",
        "train_sentiments=reviews_data.sentiment[:40000]\n",
        "#test dataset\n",
        "test_reviews=reviews_data.review[40000:45000]\n",
        "test_sentiments=reviews_data.sentiment[40000:45000]\n",
        "#validation (blind) dataset\n",
        "blind_reviews=reviews_data.review[45000:]\n",
        "blind_sentiments=reviews_data.sentiment[45000:]\n",
        "print(train_reviews.shape,train_sentiments.shape)\n",
        "print(test_reviews.shape,test_sentiments.shape)\n",
        "print(blind_reviews.shape,blind_sentiments.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000,) (40000,)\n",
            "(5000,) (5000,)\n",
            "(5000,) (5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eewcC9Jh61_R",
        "colab_type": "code",
        "outputId": "87f41c4f-2fec-4bf7-b6e4-358eaaaf2cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# CountVectorizer implements both tokenization and occurrence counting in a single class. Read more here https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "# You can also reuse the from scratch code we learnt in previous class\n",
        "# TfidfVectorizer Convert a collection of raw documents to a matrix of TF-IDF features. Equivalent to CountVectorizer followed by TfidfTransformer.\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#Count vectorizer with \n",
        "lower_count_thr = 100 # rare words/tokens\n",
        "upper_count_thr = 5000 # frequent/common tokens\n",
        "\n",
        "tv=TfidfVectorizer(min_df=lower_count_thr,max_df=upper_count_thr,binary=False,ngram_range=(1,1))\n",
        "#transformed train reviews\n",
        "tv_train_reviews=tv.fit_transform(train_reviews)\n",
        "#transformed test reviews\n",
        "tv_test_reviews=tv.transform(test_reviews)\n",
        "\n",
        "#transformed validation reviews\n",
        "tv_blind_reviews=tv.transform(blind_reviews)\n",
        "\n",
        "print('BOW_cv_train:',tv_train_reviews.shape)\n",
        "print('BOW_cv_test:',tv_test_reviews.shape)\n",
        "print('BOW_cv_blind:',tv_blind_reviews.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOW_cv_train: (40000, 5144)\n",
            "BOW_cv_test: (5000, 5144)\n",
            "BOW_cv_blind: (5000, 5144)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvXxkXwb7B8-",
        "colab_type": "code",
        "outputId": "2caf26fa-7fb5-4d6a-845c-cfb00d6b5b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Now generate binary (true, false) labels from sentiment values. positive maps to 1, negative maps to 0\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb=LabelBinarizer()\n",
        "#transformed sentiment data\n",
        "sentiment_data=lb.fit_transform(reviews_data['sentiment'])\n",
        "print(sentiment_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJVDrvGP7CKV",
        "colab_type": "code",
        "outputId": "ae0ddaec-d08f-41bf-e96f-0dae88d0ce42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Spliting the sentiment data\n",
        "train_sentiments=sentiment_data[:40000]\n",
        "test_sentiments=sentiment_data[40000:45000]\n",
        "blind_sentiments=sentiment_data[45000:]\n",
        "print(train_sentiments.shape)\n",
        "print(test_sentiments.shape)\n",
        "print(blind_sentiments.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 1)\n",
            "(5000, 1)\n",
            "(5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkwrwkFh_nBD",
        "colab_type": "text"
      },
      "source": [
        "Now that we have both vectorized data and binary lables we are ready to train classifier model. The objective of binary classifier is to predict 0/1 label based on features. We use many types of classifier for comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKmEKYkB7Cec",
        "colab_type": "code",
        "outputId": "653c5d6f-2b55-4093-b2eb-70bb9358a890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "#training Logistic model\n",
        "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
        "#Fitting the model for tfidf features\n",
        "lr_tfidf=lr.fit(tv_train_reviews,train_sentiments)\n",
        "print(lr_tfidf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7DBP1dqAIrC",
        "colab_type": "text"
      },
      "source": [
        "Now we use the trained model to predict sentiment label on both test and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whqgNKY-7EV2",
        "colab_type": "code",
        "outputId": "9913acf4-d271-4017-9930-338f62496e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##Predicting the model for test set\n",
        "lr_tfidf_predict_test=lr.predict(tv_test_reviews)\n",
        "print(lr_tfidf_predict_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0qfHp9HDJe3",
        "colab_type": "text"
      },
      "source": [
        "Next we compute accuracy of the prediction on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tp5hUusDQGl",
        "colab_type": "code",
        "outputId": "acad5094-b3ca-46d2-b650-cfb181810d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "lr_tfidf_score=accuracy_score(test_sentiments,lr_tfidf_predict_test)\n",
        "print(\"lr_tfidf_score :\",lr_tfidf_score)\n",
        "\n",
        "#Classification report for tfidf features\n",
        "lr_tfidf_report_test=classification_report(test_sentiments,lr_tfidf_predict_test,target_names=['Positive','Negative'])\n",
        "print(lr_tfidf_report_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr_tfidf_score : 0.882\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.89      0.87      0.88      2463\n",
            "    Negative       0.88      0.89      0.88      2537\n",
            "\n",
            "    accuracy                           0.88      5000\n",
            "   macro avg       0.88      0.88      0.88      5000\n",
            "weighted avg       0.88      0.88      0.88      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
